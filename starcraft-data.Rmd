---
title: "RedDwarfData: a simplified dataset of StarCraft matches"
author: "J. J. Merelo"
date: "27 de noviembre de 2017"
output: pdf_document
abstract: Starcraft is one of the most interesting arenas to test new machine learning and computational intelligence techniques; however, StarCraft matches take a long time and creating a good dataset for training can be hard; besides, analyzing match logs to extract the main characteristics can also be done in many different ways to the point that extracting and processing data itself can take an inordinate amount of time. In this paper we present one such simplified dataset extracted from Robinson and Watson, which we have called RedDwarfData, containing several thousand matches processed to frames, so that temporal studies can also be undertaken. This dataset is available under a free license. An initial analysis and appraisal of these matches is also made. 
bibliography: prediction.bib
---

```{r setup, include=FALSE}
```

# Introduction

\emph{StarCraft} is a well-known Real Time Strategy (\emph{RTS}) game whose first version was released in 1998. The game consists of two opponents trying to beat each other over a squared arena. Every player has to build workers and buildings using the available resources located over the terrain. There exit three different kinds of species, any of then having different kinds of individuals. Species and individual differ in their skills, so that players have a wide range of possibilities in order to plan their strategies. The need to dynamically take decisions for both the short and the long terms make RTS adequate scenarios to test AI algorithms [@ontanon2013survey] that could be used later in real problems including financial, military and logistics problems. 

\emph{StarCraft} has become popular among researchers thanks to \emph{BWAPI}, an API developed by the community that allows programming artificial agents and that was developed for StarCraft competitions [@buro2012real]. These agents can act just like regular players, according to a previously established algorithm; but, more important, they can collectse data as matches are running. The data collected this way can be later analysed, so that machine learning techniques can be applied for both supervised and unsupervised learning.

Developing and releasing datasets for this task is thus a way of expanding research in this area and allowing researchers to develop their own bots or prediction algorithms without having to scrape them or actually play the games, a time-consuming task, to extract data from them. Several researchers have done so and we will refer to them in the state of the art; in this paper we part from Robertson and Watson's dataset [@RobertsonW14] and create a simpler one that can be used without needing many resources; even so, the data set is balanced with respect to duration, races and number of resources used by the players. 

The rest of the paper is organized as follows: next we will present the Starcraft datasets that have been published so far. In the next section we will show how Robertson and Watson's dataset was processed and the rationale for doing it that way. Then we will present a macro picture of the data set, to eventually draw some conclusions from it and possible lines of work using this dataset.

## State of the art

The main motivation for writing this paper was the proliferation of StarCraft datasets in the last few years. Players have been uploading their matches to several websites, such as TeamLiquid or CC, since... This dataset are usually used by the player community to learn new playing techniques from other players. However, these datasets are in raw form and require some kind of parsing and filtering in order to LISTA DE STARDATA. Moreover, a lot of uploaded replays may be corrupt or incomplete. Different authors have been processing these replays to create datasets that can be used to predict the outcome of a match or a battle. First paper that describes the processing of replays was the one presented by Ravari et \cite{Ravari09}, where they processed replays to create a dataset to apply WHATEVER. The number of replays was XXXX.

Robertson and Watson

Recently, the work by Lin et al. \cite{Stardata17} presented the largest dataset to date. It includes 65646 replays, storing the full state of the game, including up to 30 feature by unit and battle detections. Even using compression mechanisms, this dataset requires 365GB of space. 

## Data extraction and filtering

The data was obtained from whoever dataset, and then we proceeded to process it.

## The big picture

A few macro analysis of the data in this dataset will allow us to compare it with other datasets and also appraise its balance and general features. The duration of the matches is represented below.

**Include R code for histogram here**

The mode is between 20 and 25 minutes, with average equal to **include variables here** and median **include median**. 

## Conclusions

## References